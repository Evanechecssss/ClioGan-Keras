{"cells":[{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"source_hash":null,"execution_start":1703125988959,"execution_millis":3307,"deepnote_to_be_reexecuted":false,"cell_id":"613fe05b617a4b368a76039d9606f206","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nimport os\nimport pickle\nimport re\n\n\nfrom PIL import Image\n\nfrom typing import Union, List, Callable\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, Activation\nfrom keras.layers import BatchNormalization, Concatenate, Dropout","block_group":"e07fa8bc26b3413f9b7ca160437eb0d7","execution_count":null,"outputs":[{"name":"stderr","text":"2023-12-21 02:33:08.959712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-12-21 02:33:09.177815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-12-21 02:33:09.177855: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-12-21 02:33:09.246968: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-12-21 02:33:10.714740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-12-21 02:33:10.714890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-12-21 02:33:10.714912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"source_hash":null,"execution_start":1703125992311,"execution_millis":102933,"deepnote_to_be_reexecuted":false,"cell_id":"887b43a0fd2f446f9cc8fe15ab4d9609","deepnote_cell_type":"code"},"source":"! pip install rembg\nfrom rembg import remove","block_group":"bdc4c074d8fd4aae9ae0b2987cfc67a3","execution_count":null,"outputs":[{"name":"stdout","text":"Collecting rembg\n  Downloading rembg-2.0.53-py3-none-any.whl (32 kB)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (1.23.4)\nCollecting scikit-image\n  Downloading scikit_image-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pooch\n  Downloading pooch-1.8.0-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (9.2.0)\nCollecting onnxruntime\n  Downloading onnxruntime-1.16.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pymatting\n  Downloading PyMatting-1.1.12-py3-none-any.whl (52 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opencv-python-headless\n  Downloading opencv_python_headless-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (4.64.1)\nRequirement already satisfied: jsonschema in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from rembg) (3.2.0)\nRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (1.9.3)\nRequirement already satisfied: six>=1.11.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jsonschema->rembg) (1.16.0)\nRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from jsonschema->rembg) (58.1.0)\nRequirement already satisfied: attrs>=17.4.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jsonschema->rembg) (22.1.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jsonschema->rembg) (0.18.1)\nCollecting coloredlogs\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from onnxruntime->rembg) (21.3)\nRequirement already satisfied: protobuf in /shared-libs/python3.9/py/lib/python3.9/site-packages (from onnxruntime->rembg) (3.19.6)\nRequirement already satisfied: sympy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from onnxruntime->rembg) (1.11.1)\nRequirement already satisfied: flatbuffers in /shared-libs/python3.9/py/lib/python3.9/site-packages (from onnxruntime->rembg) (22.9.24)\nRequirement already satisfied: requests>=2.19.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pooch->rembg) (2.28.1)\nCollecting platformdirs>=2.5.0\n  Downloading platformdirs-4.1.0-py3-none-any.whl (17 kB)\nCollecting numba!=0.49.0\n  Downloading numba-0.58.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tifffile>=2022.8.12\n  Downloading tifffile-2023.12.9-py3-none-any.whl (223 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting lazy_loader>=0.3\n  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\nCollecting imageio>=2.27\n  Downloading imageio-2.33.1-py3-none-any.whl (313 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting networkx>=2.8\n  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting llvmlite<0.42,>=0.41.0dev0\n  Downloading llvmlite-0.41.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging->onnxruntime->rembg) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (2022.9.24)\nCollecting humanfriendly>=9.1\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from sympy->onnxruntime->rembg) (1.2.1)\nInstalling collected packages: tifffile, platformdirs, opencv-python-headless, networkx, llvmlite, lazy_loader, imageio, humanfriendly, scikit-image, pooch, numba, coloredlogs, pymatting, onnxruntime, rembg\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 imageio-2.33.1 lazy_loader-0.3 llvmlite-0.41.1 networkx-3.2.1 numba-0.58.1 onnxruntime-1.16.3 opencv-python-headless-4.8.1.78 platformdirs-4.1.0 pooch-1.8.0 pymatting-1.1.12 rembg-2.0.53 scikit-image-0.22.0 tifffile-2023.12.9\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"source_hash":null,"execution_start":1703126095236,"execution_millis":28,"deepnote_to_be_reexecuted":false,"cell_id":"c0c7be7f59f34a6a87db85ef72a33ec2","deepnote_cell_type":"code"},"source":"data_path_ser = 'Data71/'\ndata_path = 'ImageData71'\nimage_resolution = (256, 256, 1)\nstep = 3","block_group":"876fc5313cb64d43a89042fbe31fb150","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"source_hash":null,"execution_start":1703127338333,"execution_millis":18575,"deepnote_to_be_reexecuted":false,"cell_id":"70204dc0239d47e19aec8d9cdbb38f2a","deepnote_cell_type":"code"},"source":"class Batch:\n    def __init__(self, ident: str):\n        self.input_images = list()\n        self.expected_images = list()\n        self.ident = ident\n\n    def __str__(self) -> str:\n       return f\"Batch_{self.ident}: images:{self.images(len)}, expected:{self.expected(len)}\"\n    \n    # images and expected functions return element of array from index or length of array\n    def images(self, n: Union[int, Callable]) -> Union[tf.Tensor, int]:\n      return len(self.input_images) if isinstance(n, type(len)) else self.input_images[min(abs(n), len(self.input_images) - 1) * (-1) ** (n < 0)]\n\n    def expected(self, n: Union[int, Callable]) -> Union[tf.Tensor, int]:\n      return len(self.expected_images) if isinstance(n, type(len)) else self.expected_images[min(abs(n), len(self.expected_images) - 1) * (-1) ** (n < 0)]\n\ndef load_image(image_source: str, remove_bg = False) -> tf.Tensor:\n    if re.match(\"^(http|https):\\/\\/\", image_source):\n        image = Image.open(BytesIO(requests.get(image_source).content))\n    else:\n        image = Image.open(image_source)\n        \n    if remove_bg:\n        image = remove(image)\n        jpg_image = Image.new(\"RGB\", image.size, (255, 255, 255))\n        jpg_image.paste(image, (0, 0), image)\n        image = jpg_image\n    image = tf.convert_to_tensor(np.array(image))\n    image = tf.image.resize(image, image_resolution[:2])\n    image = tf.image.rgb_to_grayscale(image)\n    image.set_shape(image_resolution)\n    image /= 255.0\n    return image\n\ndef load_real_dataset() -> list[Batch]:\n    \"\"\"\n    Example of file name: ident_type_number\n    Where Ident is unic Identifier of Batch\n    Type is i (input) / e (expected)\n    \"\"\"\n\n    batches = {}\n    first_file_ident = lambda x: x.split(\"_\")[0]\n\n    def get_ident_with_batch(x: str) -> int:\n        k = first_file_ident(x)\n        if str(k) not in batches:\n            batches[str(k)] = Batch(str(k))\n        return k\n\n    def get_number(x: str) -> int:\n      return int(x.split(\"_\")[2].split(\".\")[0])\n\n    sorted_list = sorted(os.listdir(data_path),  key=lambda x: (get_ident_with_batch(x), get_number(x)))\n    for filename in sorted_list:\n        ident = first_file_ident(filename)\n        batch = batches[str(ident)]\n        if filename.startswith(f\"{ident}_i\"):\n            batch.input_images.append(load_image(filename, remove_bg=True))\n        elif filename.startswith(f\"{ident}_e\"):\n            batch.expected_images.append(load_image(filename))\n        batches[str(ident)] = batch\n    return list(batches.values())\n\ndef load_batches(load_base=True) -> list[Batch]:\n    if not os.path.exists(data_path_ser) and load_base:\n        os.makedirs(data_path_ser)\n        dataset = load_real_dataset()\n        for i in range(len(dataset)):\n            with open(f'{data_path_ser}serialized_batch{i}.txt', 'wb') as file:\n                file.write(pickle.dumps(dataset[i]))\n\n    batches = []\n    for filename in os.listdir(data_path_ser):\n        with open(data_path_ser+filename, 'rb') as file:\n            loaded_class = pickle.loads(file.read())\n            batches.append(loaded_class)\n    return batches\n\nbatches = load_batches(False)\n","block_group":"643c562b18e84df7ab31a65542a5053a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"source_hash":null,"execution_start":1703126262195,"execution_millis":85,"deepnote_to_be_reexecuted":false,"cell_id":"5d32936a3d0c4a33ae89a014ba921df7","deepnote_cell_type":"code"},"source":"class GANContainer:\n    def __init__(self, step, dataset):\n        self._img_shape = (256, 256, 1)\n        self._step = step\n        self.dataset = dataset\n        self.conv2d_kernel_init = RandomNormal(stddev=0.02)\n        \n        self._gen = self.__built_generator()\n        self._dis = self.__built_discriminator()\n        self._gan = self.__built_gan()\n\n        self._dis.summary()\n        \n        opt = Adam(lr=0.0002, beta_1=0.5)\n        losses = ['binary_crossentropy', 'mae']\n        self._dis.compile(loss=losses[0], optimizer=opt, loss_weights=[0.5])\n        self._gan.compile(loss=losses, optimizer=opt, loss_weights=[1, 100])\n        \n    def __built_discriminator(self):\n        in_src = Input(shape=self._img_shape)\n        in_target = Input(shape=self._img_shape)\n        merged = Concatenate()([in_src, in_target])\n\n        d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(merged)\n        d = LeakyReLU(alpha=0.2)(d)\n\n        features_strides = [(128, 2), (256, 2), (512, 2), (512, 1)]\n        for feature, stride in features_strides:\n            d = Conv2D(feature, 4, stride, padding='same', kernel_initializer=self.conv2d_kernel_init)(d)\n            d = BatchNormalization()(d)\n            d = LeakyReLU(alpha=0.2)(d)\n\n        d = Conv2D(1, (4,4), padding='same', kernel_initializer=self.conv2d_kernel_init)(d)\n        patch_out = Activation('sigmoid')(d)\n\n        model = Model([in_src, in_target], patch_out)\n        return model\n\n    def __encoder_block(self, layer_in, n_filters, batchnorm=True):\n        g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(layer_in)\n        if batchnorm:\n            g = BatchNormalization()(g, training=True)\n        g = LeakyReLU(alpha=0.2)(g)\n        return g\n\n    def __decoder_block(self, layer_in, skip_in, n_filters, dropout=True):\n        g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(layer_in)\n        g = BatchNormalization()(g, training=True)\n        if dropout:\n            g = Dropout(0.5)(g, training=True)\n        g = Concatenate()([g, skip_in])\n        g = Activation('relu')(g)\n        return g\n\n    def __built_generator(self):\n        in_image = Input(shape=self._img_shape)\n\n        e1 = self.__encoder_block(in_image, 64, batchnorm=False)\n        e2 = self.__encoder_block(e1, 128)\n        e3 = self.__encoder_block(e2, 256)\n        e4 = self.__encoder_block(e3, 512)\n        e5 = self.__encoder_block(e4, 512)\n        e6 = self.__encoder_block(e5, 512)\n        e7 = self.__encoder_block(e6, 512)\n\n        b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(e7)\n        b = Activation('relu')(b)\n\n        d1 = self.__decoder_block(b, e7, 512)\n        d2 = self.__decoder_block(d1, e6, 512)\n        d3 = self.__decoder_block(d2, e5, 512)\n        d4 = self.__decoder_block(d3, e4, 512, dropout=False)\n        d5 = self.__decoder_block(d4, e3, 256, dropout=False)\n        d6 = self.__decoder_block(d5, e2, 128, dropout=False)\n        d7 = self.__decoder_block(d6, e1, 64, dropout=False)\n\n        g = Conv2DTranspose(self._img_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(d7) #Modified \n        out_image = Activation('tanh')(g)\n        model = Model(in_image, out_image)\n        return model\n\n    def __built_gan(self):\n        for layer in self._dis.layers:\n            if not isinstance(layer, BatchNormalization):\n                layer.trainable = False \n\n        in_src = Input(shape=self._img_shape)\n        gen_out = self._gen(in_src)\n        dis_out = self._dis([in_src, gen_out])\n        model = Model(in_src, [dis_out, gen_out])\n        return model\n\n    def __save_actual_result(self, tensor, name, folder='result'):\n        keras.utils.array_to_img(tensor).save(f'{folder}/{self._step}s{name}e.jpg')\n            \n    def train(self, epochs=501, save_interval=50):\n        patch_shape = self._dis.output_shape[1]\n        valid = np.ones((1, patch_shape, patch_shape, 1))\n        fake = np.zeros((1, patch_shape, patch_shape, 1))\n        for epoch in range(epochs):\n            batch = np.random.choice(self.dataset)\n            \n            img_in = tf.expand_dims(batch.images(0), axis=0) \n            img_exp = tf.expand_dims(batch.expected(self._step), axis=0) \n\n            gen_img = self._gen.predict(img_in)\n \n            d_loss_gen_img = self._dis.train_on_batch([img_in, gen_img], fake)\n            d_loss_img_in = self._dis.train_on_batch([img_in, img_in], fake)\n            d_loss_img_exp = self._dis.train_on_batch([img_in, img_exp], valid)\n            d_loss_in_out = self._dis.train_on_batch([img_in, img_in * img_exp], fake)\n\n            g_loss, _, _ = self._gan.train_on_batch(img_in, [valid, img_exp])\n        \n            print(f\"[{epoch}/{epochs}], G_loss:{g_loss}, D_g_img:{d_loss_gen_img}, D_g_in:{d_loss_img_in}, D_exp:{d_loss_img_exp}, D_mult:{d_loss_in_out}\")\n\n            if epoch % save_interval == 0:\n                self.__save_actual_result(gen_img[0,:,:,:], str(epoch))\n                \n    def save_models(self, folder=None):\n        if folder is None:\n            folder=str(self._step)+'/'\n        self._gen.save(f'{folder}gen')\n        self._dis.save(f'{folder}dis')","block_group":"e12f77c99d6e4ee2bf3b67ffe3a0fe04","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"source_hash":null,"execution_start":1703126266937,"execution_millis":4752,"deepnote_to_be_reexecuted":false,"cell_id":"d045cec9ea3f4159a4d28a0cc076dbf0","deepnote_cell_type":"code"},"source":"gan_cont = GANContainer(step, batches)","block_group":"f82fc955a6284833a36c372c2516fb57","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n  warnings.warn(\nModel: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_6 (InputLayer)           [(None, 256, 256, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n input_7 (InputLayer)           [(None, 256, 256, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n concatenate_15 (Concatenate)   (None, 256, 256, 2)  0           ['input_6[0][0]',                \n                                                                  'input_7[0][0]']                \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 128, 128, 64  2112        ['concatenate_15[0][0]']         \n                                )                                                                 \n                                                                                                  \n leaky_re_lu_19 (LeakyReLU)     (None, 128, 128, 64  0           ['conv2d_22[0][0]']              \n                                )                                                                 \n                                                                                                  \n conv2d_23 (Conv2D)             (None, 64, 64, 128)  131200      ['leaky_re_lu_19[0][0]']         \n                                                                                                  \n batch_normalization_30 (BatchN  (None, 64, 64, 128)  512        ['conv2d_23[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n leaky_re_lu_20 (LeakyReLU)     (None, 64, 64, 128)  0           ['batch_normalization_30[0][0]'] \n                                                                                                  \n conv2d_24 (Conv2D)             (None, 32, 32, 256)  524544      ['leaky_re_lu_20[0][0]']         \n                                                                                                  \n batch_normalization_31 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_24[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n leaky_re_lu_21 (LeakyReLU)     (None, 32, 32, 256)  0           ['batch_normalization_31[0][0]'] \n                                                                                                  \n conv2d_25 (Conv2D)             (None, 16, 16, 512)  2097664     ['leaky_re_lu_21[0][0]']         \n                                                                                                  \n batch_normalization_32 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_25[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n leaky_re_lu_22 (LeakyReLU)     (None, 16, 16, 512)  0           ['batch_normalization_32[0][0]'] \n                                                                                                  \n conv2d_26 (Conv2D)             (None, 16, 16, 512)  4194816     ['leaky_re_lu_22[0][0]']         \n                                                                                                  \n batch_normalization_33 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_26[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n leaky_re_lu_23 (LeakyReLU)     (None, 16, 16, 512)  0           ['batch_normalization_33[0][0]'] \n                                                                                                  \n conv2d_27 (Conv2D)             (None, 16, 16, 1)    8193        ['leaky_re_lu_23[0][0]']         \n                                                                                                  \n activation_19 (Activation)     (None, 16, 16, 1)    0           ['conv2d_27[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 6,964,161\nTrainable params: 2,816\nNon-trainable params: 6,961,345\n__________________________________________________________________________________________________\n/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"source_hash":null,"execution_start":1703126118916,"execution_millis":17665,"deepnote_to_be_reexecuted":false,"cell_id":"506711551a5c4eb7be501aea44c4a3c8","deepnote_cell_type":"code"},"source":"gan_cont.train(epochs=11, save_interval=5)\ngan_cont.save_models()","block_group":"32b0b156435042ff85ac6b41152587df","execution_count":null,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\n[0/11], G_loss:90.68773651123047, D_g_img:0.534294605255127, D_g_in:0.5527071952819824, D_exp:0.2990652918815613, D_mult:0.5459594130516052\n","output_type":"stream"},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'result/3s0e.jpg'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgan_cont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m gan_cont\u001b[38;5;241m.\u001b[39msave_models()\n","Cell \u001b[0;32mIn [5], line 116\u001b[0m, in \u001b[0;36mGANContainer.train\u001b[0;34m(self, epochs, save_interval)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], G_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, D_g_img:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss_gen_img\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, D_g_in:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss_img_in\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, D_exp:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss_img_exp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, D_mult:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss_in_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m save_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__save_actual_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_img\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn [5], line 92\u001b[0m, in \u001b[0;36mGANContainer.__save_actual_result\u001b[0;34m(self, tensor, name, folder)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__save_actual_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, name, folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43me.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/PIL/Image.py:2317\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2320\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result/3s0e.jpg'"]}]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e1e341d8-6db6-4ef5-9a6a-7226f58f39f3' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"aa7eba51a24b4c97a556373fa9bb758f","deepnote_execution_queue":[]}}
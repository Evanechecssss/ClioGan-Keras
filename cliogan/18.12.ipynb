{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "execution_start": 1702902500962,
    "execution_millis": 6216,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "955ccf5ee2784333b2cf42b7bc4e6764",
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, Activation\n",
    "from keras.layers import BatchNormalization, Concatenate, Dropout"
   ],
   "block_group": "e07fa8bc26b3413f9b7ca160437eb0d7",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "2023-12-18 12:28:20.936342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-12-18 12:28:21.224435: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-12-18 12:28:21.224469: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-12-18 12:28:21.272953: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-12-18 12:28:25.346273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-12-18 12:28:25.346380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-12-18 12:28:25.346397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "execution_start": 1702902507181,
    "execution_millis": 58506,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "33776a4759e6424ebaeccad50659787d",
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "! pip install rembg\n",
    "from rembg import remove"
   ],
   "block_group": "bdc4c074d8fd4aae9ae0b2987cfc67a3",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting rembg\n  Downloading rembg-2.0.53-py3-none-any.whl (32 kB)\nCollecting onnxruntime\n  Downloading onnxruntime-1.16.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.4/6.4 MB\u001B[0m \u001B[31m86.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: pillow in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (9.2.0)\nRequirement already satisfied: tqdm in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (4.64.1)\nCollecting pooch\n  Downloading pooch-1.8.0-py3-none-any.whl (62 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m15.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: jsonschema in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from rembg) (3.2.0)\nRequirement already satisfied: scipy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (1.9.3)\nCollecting pymatting\n  Downloading PyMatting-1.1.12-py3-none-any.whl (52 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.0/53.0 kB\u001B[0m \u001B[31m15.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting opencv-python-headless\n  Downloading opencv_python_headless-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.1/49.1 MB\u001B[0m \u001B[31m34.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from rembg) (1.23.4)\nCollecting scikit-image\n  Downloading scikit_image-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.7/14.7 MB\u001B[0m \u001B[31m53.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: setuptools in /root/venv/lib/python3.9/site-packages (from jsonschema->rembg) (58.1.0)\nRequirement already satisfied: six>=1.11.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jsonschema->rembg) (1.16.0)\nRequirement already satisfied: attrs>=17.4.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jsonschema->rembg) (22.1.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from jsonschema->rembg) (0.18.1)\nRequirement already satisfied: flatbuffers in /shared-libs/python3.9/py/lib/python3.9/site-packages (from onnxruntime->rembg) (22.9.24)\nRequirement already satisfied: packaging in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from onnxruntime->rembg) (21.3)\nCollecting coloredlogs\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: protobuf in /shared-libs/python3.9/py/lib/python3.9/site-packages (from onnxruntime->rembg) (3.19.6)\nRequirement already satisfied: sympy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from onnxruntime->rembg) (1.11.1)\nRequirement already satisfied: requests>=2.19.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pooch->rembg) (2.28.1)\nCollecting platformdirs>=2.5.0\n  Downloading platformdirs-4.1.0-py3-none-any.whl (17 kB)\nCollecting numba!=0.49.0\n  Downloading numba-0.58.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m98.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting tifffile>=2022.8.12\n  Downloading tifffile-2023.12.9-py3-none-any.whl (223 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m223.6/223.6 kB\u001B[0m \u001B[31m32.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting lazy_loader>=0.3\n  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\nCollecting networkx>=2.8\n  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m92.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting imageio>=2.27\n  Downloading imageio-2.33.1-py3-none-any.whl (313 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m313.3/313.3 kB\u001B[0m \u001B[31m29.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting llvmlite<0.42,>=0.41.0dev0\n  Downloading llvmlite-0.41.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.6/43.6 MB\u001B[0m \u001B[31m27.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging->onnxruntime->rembg) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from requests>=2.19.0->pooch->rembg) (3.4)\nCollecting humanfriendly>=9.1\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m16.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: mpmath>=0.19 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from sympy->onnxruntime->rembg) (1.2.1)\nInstalling collected packages: tifffile, platformdirs, opencv-python-headless, networkx, llvmlite, lazy_loader, imageio, humanfriendly, scikit-image, pooch, numba, coloredlogs, pymatting, onnxruntime, rembg\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 imageio-2.33.1 lazy_loader-0.3 llvmlite-0.41.1 networkx-3.2.1 numba-0.58.1 onnxruntime-1.16.3 opencv-python-headless-4.8.1.78 platformdirs-4.1.0 pooch-1.8.0 pymatting-1.1.12 rembg-2.0.53 scikit-image-0.22.0 tifffile-2023.12.9\n\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "execution_start": 1702902565730,
    "execution_millis": 8,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "591fba688deb4f8089896e52b7640cd5",
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "data_path_ser = 'Data71/'\n",
    "image_resolution = (256, 256, 1)\n",
    "step = 3"
   ],
   "block_group": "876fc5313cb64d43a89042fbe31fb150",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "execution_start": 1702902565731,
    "execution_millis": 22821,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "70aca34a9ebb429392dfa6c5f4d0b326",
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class Batch:\n",
    "    def __init__(self, ident):\n",
    "        self.input_images = list()\n",
    "        self.expected_images = list()\n",
    "        self.ident = ident\n",
    "\n",
    "    def __str__(self):\n",
    "       return f\"Batch_{self.ident}: images:{self.images(len)}, expected:{self.expected(len)}\"\n",
    "\n",
    "    def images(self, n):\n",
    "      return len(self.input_images) if isinstance(n, type(len)) else self.input_images[min(abs(n), len(self.input_images) - 1) * (-1) ** (n < 0)]\n",
    "\n",
    "    def expected(self, n):\n",
    "      return len(self.expected_images) if isinstance(n, type(len)) else self.expected_images[min(abs(n), len(self.expected_images) - 1) * (-1) ** (n < 0)]\n",
    "\n",
    "def load_image(image_path, remove_bg = False):\n",
    "    image = Image.open(image_path)\n",
    "    if remove_bg:\n",
    "        image = remove(image)\n",
    "        jpg_image = Image.new(\"RGB\", image.size, (255, 255, 255))\n",
    "        jpg_image.paste(image, (0, 0), image)\n",
    "        image = jpg_image\n",
    "    image = tf.convert_to_tensor(np.array(image))\n",
    "    image = tf.image.resize(image, image_resolution[:2])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image.set_shape(image_resolution)\n",
    "    image /= 255.0\n",
    "    return image\n",
    "\n",
    "def load_real_dataset():\n",
    "    # Этот код посвящен Кате и моим страданиям\n",
    "    batches = {}\n",
    "    def get_ident(x):\n",
    "        k = int(x.split(\"_\")[0])\n",
    "        if str(k) not in batches:\n",
    "            batches[str(k)] = Batch(str(k))\n",
    "        return k\n",
    "\n",
    "    sorted_list = sorted(os.listdir(data_path),  key=lambda x: (int(x.split(\"_\")[0]), get_ident(x)))\n",
    "    for filename in sorted_list:\n",
    "        ident = get_ident(filename)\n",
    "        if filename.startswith(f\"{ident}_i\"):\n",
    "            batch = batches[str(ident)]\n",
    "            batch.input_images.append(load_image(filename, remove_bg=True))\n",
    "            batches[str(ident)] = batch\n",
    "        if filename.startswith(f\"{ident}_e\"):\n",
    "            batch = batches[str(ident)]\n",
    "            batch.expected_images.append(load_image(filename))\n",
    "            batches[str(ident)] = batch\n",
    "    return list(batches.values())\n",
    "\n",
    "def load_batches(load_base=True):\n",
    "    if not os.path.exists(data_path_ser) and load_base:\n",
    "        os.makedirs(data_path_ser)\n",
    "        dataset = load_real_dataset()\n",
    "        for i in range(len(dataset)):\n",
    "            with open(f'{data_path_ser}serialized_batch{i}.txt', 'wb') as file:\n",
    "                file.write(pickle.dumps(dataset[i]))\n",
    "\n",
    "    batches = []\n",
    "    for filename in os.listdir(data_path_ser):\n",
    "        with open(data_path_ser+filename, 'rb') as file:\n",
    "            loaded_class = pickle.loads(file.read())\n",
    "            batches.append(loaded_class)\n",
    "    return batches\n",
    "\n",
    "batches = load_batches(False)"
   ],
   "block_group": "643c562b18e84df7ab31a65542a5053a",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "2023-12-18 12:29:37.788574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /root/venv/lib/python3.9/site-packages/cv2/../../lib64:\n2023-12-18 12:29:37.788620: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2023-12-18 12:29:37.788646: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-315008c8-cc0c-4a26-8181-909544b84f1e): /proc/driver/nvidia/version does not exist\n2023-12-18 12:29:37.789031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "execution_start": 1702902588524,
    "execution_millis": 79,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "0b563345771d42a2957ef9a364efb606",
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class GANContainer:\n",
    "    def __init__(self, step, dataset):\n",
    "        self._img_shape = (256, 256, 1)\n",
    "        self._step = step\n",
    "        self.dataset = dataset\n",
    "        self.conv2d_kernel_init = RandomNormal(stddev=0.02)\n",
    "        \n",
    "        self._gen = self.__built_generator()\n",
    "        self._dis = self.__built_discriminator()\n",
    "        self._gan = self.__built_gan()\n",
    "        \n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "        losses = ['binary_crossentropy', 'mae']\n",
    "        self._dis.compile(loss=losses[0], optimizer=opt, loss_weights=[0.5])\n",
    "        self._gan.compile(loss=losses, optimizer=opt, loss_weights=[1, 100])\n",
    "        \n",
    "    def __built_discriminator(self):\n",
    "        in_src = Input(shape=self._img_shape)\n",
    "        in_target = Input(shape=self._img_shape)\n",
    "        merged = Concatenate()([in_src, in_target])\n",
    "\n",
    "        d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(merged)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "        features_strides = [(128, 2), (256, 2), (512, 2), (512, 1)]\n",
    "        for feature, stride in features_strides:\n",
    "            d = Conv2D(feature, 4, stride, padding='same', kernel_initializer=self.conv2d_kernel_init)(d)\n",
    "            d = BatchNormalization()(d)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "        d = Conv2D(1, (4,4), padding='same', kernel_initializer=self.conv2d_kernel_init)(d)\n",
    "        patch_out = Activation('sigmoid')(d)\n",
    "\n",
    "        model = Model([in_src, in_target], patch_out)\n",
    "        return model\n",
    "\n",
    "    def __encoder_block(self, layer_in, n_filters, batchnorm=True):\n",
    "        g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(layer_in)\n",
    "        if batchnorm:\n",
    "            g = BatchNormalization()(g, training=True)\n",
    "        g = LeakyReLU(alpha=0.2)(g)\n",
    "        return g\n",
    "\n",
    "    def __decoder_block(self, layer_in, skip_in, n_filters, dropout=True):\n",
    "        g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(layer_in)\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "        if dropout:\n",
    "            g = Dropout(0.5)(g, training=True)\n",
    "        g = Concatenate()([g, skip_in])\n",
    "        g = Activation('relu')(g)\n",
    "        return g\n",
    "\n",
    "    def __built_generator(self):\n",
    "        in_image = Input(shape=self._img_shape)\n",
    "\n",
    "        e1 = self.__encoder_block(in_image, 64, batchnorm=False)\n",
    "        e2 = self.__encoder_block(e1, 128)\n",
    "        e3 = self.__encoder_block(e2, 256)\n",
    "        e4 = self.__encoder_block(e3, 512)\n",
    "        e5 = self.__encoder_block(e4, 512)\n",
    "        e6 = self.__encoder_block(e5, 512)\n",
    "        e7 = self.__encoder_block(e6, 512)\n",
    "\n",
    "        b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(e7)\n",
    "        b = Activation('relu')(b)\n",
    "\n",
    "        d1 = self.__decoder_block(b, e7, 512)\n",
    "        d2 = self.__decoder_block(d1, e6, 512)\n",
    "        d3 = self.__decoder_block(d2, e5, 512)\n",
    "        d4 = self.__decoder_block(d3, e4, 512, dropout=False)\n",
    "        d5 = self.__decoder_block(d4, e3, 256, dropout=False)\n",
    "        d6 = self.__decoder_block(d5, e2, 128, dropout=False)\n",
    "        d7 = self.__decoder_block(d6, e1, 64, dropout=False)\n",
    "\n",
    "        g = Conv2DTranspose(self._img_shape[2], (4,4), strides=(2,2), padding='same', kernel_initializer=self.conv2d_kernel_init)(d7) #Modified \n",
    "        out_image = Activation('tanh')(g)\n",
    "        model = Model(in_image, out_image)\n",
    "        return model\n",
    "\n",
    "    def __built_gan(self):\n",
    "        for layer in self._dis.layers:\n",
    "            if not isinstance(layer, BatchNormalization):\n",
    "                layer.trainable = False \n",
    "\n",
    "        in_src = Input(shape=self._img_shape)\n",
    "        gen_out = self._gen(in_src)\n",
    "        dis_out = self._dis([in_src, gen_out])\n",
    "        model = Model(in_src, [dis_out, gen_out])\n",
    "        return model\n",
    "\n",
    "    def __save_actual_result(self, tensor, name, folder='result'):\n",
    "        keras.utils.array_to_img(tensor).save(f'{folder}/{self._step}s{name}e.jpg')\n",
    "            \n",
    "    def train(self, epochs=501, save_interval=50):\n",
    "        patch_shape = self._dis.output_shape[1]\n",
    "        valid = np.ones((1, patch_shape, patch_shape, 1))\n",
    "        fake = np.zeros((1, patch_shape, patch_shape, 1))\n",
    "        for epoch in range(epochs):\n",
    "            batch = np.random.choice(self.dataset)\n",
    "            \n",
    "            img_in = tf.expand_dims(batch.images(0), axis=0) \n",
    "            img_exp = tf.expand_dims(batch.expected(self._step), axis=0) \n",
    "\n",
    "            gen_img = self._gen.predict(img_in)\n",
    " \n",
    "            d_loss_gen_img = self._dis.train_on_batch([img_in, gen_img], fake)\n",
    "            d_loss_img_in = self._dis.train_on_batch([img_in, img_in], fake)\n",
    "            d_loss_img_exp = self._dis.train_on_batch([img_in, img_exp], valid)\n",
    "            d_loss_in_out = self._dis.train_on_batch([img_in, img_in * img_exp], fake)\n",
    "\n",
    "            g_loss, _, _ = self._gan.train_on_batch(img_in, [valid, img_exp])\n",
    "        \n",
    "            print(f\"[{epoch}/{epochs}], G_loss:{g_loss}, D_g_img:{d_loss_gen_img}, D_g_in:{d_loss_img_in}, D_exp:{d_loss_img_exp}, D_mult:{d_loss_in_out}\")\n",
    "\n",
    "            if epoch % save_interval == 0:\n",
    "                self.__save_actual_result(gen_img[0,:,:,:], str(epoch))\n",
    "                \n",
    "    def save_models(self, folder=None):\n",
    "        if folder is None:\n",
    "            folder=str(self._step)+'/'\n",
    "        self._gen.save(f'{folder}gen')\n",
    "        self._dis.save(f'{folder}dis')"
   ],
   "block_group": "e12f77c99d6e4ee2bf3b67ffe3a0fe04",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "execution_start": 1702902588539,
    "execution_millis": 3079,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "ffbfde90bff34726b3d9fd198e85b427",
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "gan_cont = GANContainer(step, batches)"
   ],
   "block_group": "f82fc955a6284833a36c372c2516fb57",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": null,
    "execution_start": 1702902591571,
    "execution_millis": 104900,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "213e3d3318c24d0493c80708f611c25b",
    "deepnote_cell_type": "code",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "gan_cont.train(epochs=11, save_interval=5)\n",
    "gan_cont.save_models()"
   ],
   "block_group": "32b0b156435042ff85ac6b41152587df",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n1/1 [==============================] - 1s 788ms/step\n[0/11], G_loss:96.54580688476562, D_g_img:0.4173285961151123, D_g_in:0.4033113718032837, D_exp:0.4156193733215332, D_mult:0.3998527526855469\n1/1 [==============================] - 1s 720ms/step\n[1/11], G_loss:92.27559661865234, D_g_img:0.43640995025634766, D_g_in:0.41394227743148804, D_exp:0.4101741313934326, D_mult:0.41810306906700134\n1/1 [==============================] - 1s 1s/step\n[2/11], G_loss:87.5699462890625, D_g_img:0.45903709530830383, D_g_in:0.4029954969882965, D_exp:0.41976815462112427, D_mult:0.4047125577926636\n1/1 [==============================] - 1s 751ms/step\n[3/11], G_loss:82.04061126708984, D_g_img:0.4678940176963806, D_g_in:0.4139374792575836, D_exp:0.4152517318725586, D_mult:0.4184057414531708\n1/1 [==============================] - 1s 759ms/step\n[4/11], G_loss:75.48152160644531, D_g_img:0.46191325783729553, D_g_in:0.43998950719833374, D_exp:0.3922046422958374, D_mult:0.43984454870224\n1/1 [==============================] - 1s 773ms/step\n[5/11], G_loss:69.5988540649414, D_g_img:0.4386068284511566, D_g_in:0.41534698009490967, D_exp:0.4156734049320221, D_mult:0.4141761362552643\n1/1 [==============================] - 1s 744ms/step\n[6/11], G_loss:64.119873046875, D_g_img:0.4529384672641754, D_g_in:0.4441069960594177, D_exp:0.40261879563331604, D_mult:0.4379466772079468\n1/1 [==============================] - 1s 829ms/step\n[7/11], G_loss:59.283512115478516, D_g_img:0.4317864179611206, D_g_in:0.4111376702785492, D_exp:0.4028598368167877, D_mult:0.41299968957901\n1/1 [==============================] - 1s 787ms/step\n[8/11], G_loss:55.80946350097656, D_g_img:0.43717288970947266, D_g_in:0.4219655692577362, D_exp:0.4113221764564514, D_mult:0.42457735538482666\n1/1 [==============================] - 1s 765ms/step\n[9/11], G_loss:52.876365661621094, D_g_img:0.43724286556243896, D_g_in:0.41037461161613464, D_exp:0.4153163731098175, D_mult:0.41527479887008667\n1/1 [==============================] - 1s 869ms/step\n[10/11], G_loss:48.54720687866211, D_g_img:0.42546510696411133, D_g_in:0.3949291408061981, D_exp:0.405274897813797, D_mult:0.405473917722702\nWARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\nWARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\nINFO:tensorflow:Assets written to: 3/gen/assets\nINFO:tensorflow:Assets written to: 3/gen/assets\nWARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\nINFO:tensorflow:Assets written to: 3/dis/assets\nINFO:tensorflow:Assets written to: 3/dis/assets\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=315008c8-cc0c-4a26-8181-909544b84f1e' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ],
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "deepnote": {},
  "orig_nbformat": 2,
  "deepnote_notebook_id": "d43205e2b56d48fd896453d3840e3373",
  "deepnote_execution_queue": []
 }
}